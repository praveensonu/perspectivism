{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_soft_human.csv')\n",
    "test = pd.read_csv('test_soft_human.csv')\n",
    "val = pd.read_csv('val_soft_human.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 23)\n",
      "(139, 23)\n",
      "(139, 23)\n"
     ]
    }
   ],
   "source": [
    "def no_maj(df):\n",
    "    df = df.loc[df['majority_label'] != 'No majority']\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "train = no_maj(train)\n",
    "test = no_maj(test)\n",
    "val = no_maj(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = {'Pro': 0,\n",
    "'Against': 1,\n",
    "'Neutral': 2,\n",
    "'Not-about': 3}\n",
    "\n",
    "train['labels'] = train['majority_label'].map(label_encoding)\n",
    "val['labels'] = val['majority_label'].map(label_encoding)\n",
    "test['labels'] = test['majority_label'].map(label_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['Input', 'labels']]\n",
    "val = val[['Input', 'labels']]\n",
    "test = test[['Input', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = Dataset.from_pandas(train)\n",
    "test_ = Dataset.from_pandas(test)\n",
    "val_ = Dataset.from_pandas(val)\n",
    "\n",
    "\n",
    "dataset = DatasetDict({'train': train_, 'test': test_, 'val': val_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../output/'\n",
    "model_name = 'FacebookAI/roberta-large' #google-bert/bert-large-uncased'\n",
    "model_name_filename = model_name.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    tokenized_inputs = tokenizer(examples['Input'], padding = 'max_length', truncation = True, max_length = 512)\n",
    "    tokenized_inputs['label'] = examples['labels']\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca4b41c72144987ac3a5fb24ae990b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326039ebf3014b4c9275f33466e57cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d973955cd44ac08913eca0b6501c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized = train_.map(tokenize_func, batched = True)\n",
    "val_tokenized = val_.map(tokenize_func, batched = True)\n",
    "test_tokenized = test_.map(tokenize_func, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Input', 'labels', '__index_level_0__', 'input_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 619\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized.set_format('torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "val_tokenized.set_format('torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format('torch', columns = ['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-large', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./output/baseline_{model_name_filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    \n",
    "    # Compute cross-entropy loss\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    cross_entropy = -np.sum(np.eye(probs.shape[1])[labels] * np.log(probs + 1e-9)) / len(labels)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'cross_entropy': cross_entropy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=train_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpraveenbushipaka942\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nas/users/p.bushipaka/hlt/coling/wandb/run-20240828_150507-95p7fd1h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/praveenbushipaka942/huggingface/runs/95p7fd1h' target=\"_blank\">exalted-pyramid-42</a></strong> to <a href='https://wandb.ai/praveenbushipaka942/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/praveenbushipaka942/huggingface' target=\"_blank\">https://wandb.ai/praveenbushipaka942/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/praveenbushipaka942/huggingface/runs/95p7fd1h' target=\"_blank\">https://wandb.ai/praveenbushipaka942/huggingface/runs/95p7fd1h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 06:48, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Cross Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.389500</td>\n",
       "      <td>1.373397</td>\n",
       "      <td>0.305331</td>\n",
       "      <td>0.194049</td>\n",
       "      <td>1.373424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.401200</td>\n",
       "      <td>1.361438</td>\n",
       "      <td>0.323102</td>\n",
       "      <td>0.157803</td>\n",
       "      <td>1.361593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.354200</td>\n",
       "      <td>1.340516</td>\n",
       "      <td>0.379645</td>\n",
       "      <td>0.277219</td>\n",
       "      <td>1.340549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.305500</td>\n",
       "      <td>1.236970</td>\n",
       "      <td>0.450727</td>\n",
       "      <td>0.392419</td>\n",
       "      <td>1.237038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.146800</td>\n",
       "      <td>1.041580</td>\n",
       "      <td>0.558966</td>\n",
       "      <td>0.550432</td>\n",
       "      <td>1.041462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.956400</td>\n",
       "      <td>0.692162</td>\n",
       "      <td>0.777060</td>\n",
       "      <td>0.776074</td>\n",
       "      <td>0.691982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=1.281460984547933, metrics={'train_runtime': 418.681, 'train_samples_per_second': 8.871, 'train_steps_per_second': 0.287, 'total_flos': 3461216472686592.0, 'train_loss': 1.281460984547933, 'epoch': 6.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p.bushipaka/miniconda3/envs/hlt/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6921621561050415, 'eval_accuracy': 0.777059773828756, 'eval_f1': 0.7760738264740161, 'eval_cross_entropy': 0.6919822075399713, 'eval_runtime': 7.5146, 'eval_samples_per_second': 82.373, 'eval_steps_per_second': 2.661, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_dir = f'{output_dir}/best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./output/baseline_FacebookAI-roberta-large/best_model/tokenizer_config.json',\n",
       " './output/baseline_FacebookAI-roberta-large/best_model/special_tokens_map.json',\n",
       " './output/baseline_FacebookAI-roberta-large/best_model/vocab.json',\n",
       " './output/baseline_FacebookAI-roberta-large/best_model/merges.txt',\n",
       " './output/baseline_FacebookAI-roberta-large/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(best_model_dir)\n",
    "tokenizer.save_pretrained(best_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(best_model_dir)\n",
    "model = RobertaForSequenceClassification.from_pretrained(best_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=619, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation = True, padding = 'max_length', max_length = 512).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1).tolist()[0]\n",
    "        predicted_class = np.argmax(probabilities)\n",
    "        return probabilities, predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_prob = []\n",
    "softmax_pred = []\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    text = row['Input']\n",
    "    probs, preds = predictions(text)\n",
    "    softmax_prob.append(probs)\n",
    "    softmax_pred.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['softmax_prob'] = softmax_prob\n",
    "test['softmax_preds'] = softmax_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c6a3c874e645c1b8895b8379347b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5452c7d06c942ed8b8c5c48cf535494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Multiperspective/roberta-human-label/commit/e7855687fedc6dfede5d7ef20756dd7523952c9d', commit_message='Upload tokenizer', commit_description='', oid='e7855687fedc6dfede5d7ef20756dd7523952c9d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('Multiperspective/roberta-human-label')\n",
    "tokenizer.push_to_hub('Multiperspective/roberta-human-label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.11510791366906\n",
      "Precision: 61.119791666666664\n",
      "Recall: 58.04597701149425\n",
      "F1 Score: 57.22824498586048\n",
      "Confusion Matrix:\n",
      "[[14  2 22  5]\n",
      " [ 1 19  7  2]\n",
      " [ 4  3 29  7]\n",
      " [ 2  0  6 16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44        43\n",
      "           1       0.79      0.66      0.72        29\n",
      "           2       0.45      0.67      0.54        43\n",
      "           3       0.53      0.67      0.59        24\n",
      "\n",
      "    accuracy                           0.56       139\n",
      "   macro avg       0.61      0.58      0.57       139\n",
      "weighted avg       0.60      0.56      0.55       139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = test['labels']\n",
    "y_pred = test['softmax_preds']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Precision:\", precision*100)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Recall:\", recall*100)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"F1 Score:\", f1*100)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temperature_scaling_roberta import TemperatureScalingCalibrationModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Input', 'labels', '__index_level_0__'],\n",
       "        num_rows: 619\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Input', 'labels', '__index_level_0__'],\n",
       "        num_rows: 139\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['Input', 'labels', '__index_level_0__'],\n",
       "        num_rows: 139\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Input', '__index_level_0__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332abdb2f80b44a2b1c1f721f3f60a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cd9572b20b486783661dee65bd78b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787e81bb88a54f1faf826ee007e1c388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_fn(example):\n",
    "    # Tokenize the input text\n",
    "    tokenized_example = tokenizer(example['Input'], padding='max_length', truncation=True)\n",
    "    # Add the numerical majority label\n",
    "    tokenized_example['label'] = example['labels']\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_dict = dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched= True,\n",
    "    remove_columns = columns\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:23<00:00,  3.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemperatureScalingCalibrationModule(\n",
       "  (model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_module = TemperatureScalingCalibrationModule(best_model_dir, tokenizer).to(device)\n",
    "calibration_module.fit(tokenized_dict['val'], n_epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0055], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_module.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, examples, round_digits: int = 5):\n",
    "    input_ids = examples['input_ids'].to(device)\n",
    "    attention_mask = examples['attention_mask'].to(device)\n",
    "    #token_type_ids = examples['token_type_ids'].to(device)\n",
    "    batch_labels = examples['labels'].detach().cpu().numpy().tolist()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_output = model(input_ids, attention_mask) #,token_type_ids\n",
    "\n",
    "    batch_scores = np.round(batch_output.detach().cpu().numpy(), round_digits).tolist()\n",
    "    predicted_labels = [np.argmax(scores) for scores in batch_scores]\n",
    "    return batch_scores, batch_labels, predicted_labels\n",
    "\n",
    "\n",
    "def predict_data_loader(model, data_loader: DataLoader) -> pd.DataFrame:\n",
    "    scores = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for examples in data_loader:\n",
    "        batch_scores, batch_labels, batch_pred_labels = predict(model, examples)\n",
    "        scores += batch_scores\n",
    "        true_labels += batch_labels\n",
    "        pred_labels += batch_pred_labels\n",
    "\n",
    "    df_predictions = pd.DataFrame({'scores': scores, 'original_labels': true_labels, 'pred_labels': pred_labels})\n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed:  4.149695873260498\n",
      "(139, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>original_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5756800174713135, 0.1309400051832199, 0.245...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5684800148010254, 0.04566999897360802, 0.27...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.10339999943971634, 0.06179000064730644, 0.2...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.18422000110149384, 0.042319998145103455, 0....</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.11984000355005264, 0.01844000071287155, 0.1...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              scores  original_labels  \\\n",
       "0  [0.5756800174713135, 0.1309400051832199, 0.245...                0   \n",
       "1  [0.5684800148010254, 0.04566999897360802, 0.27...                0   \n",
       "2  [0.10339999943971634, 0.06179000064730644, 0.2...                1   \n",
       "3  [0.18422000110149384, 0.042319998145103455, 0....                3   \n",
       "4  [0.11984000355005264, 0.01844000071287155, 0.1...                3   \n",
       "\n",
       "   pred_labels  \n",
       "0            0  \n",
       "1            0  \n",
       "2            3  \n",
       "3            3  \n",
       "4            3  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer, padding=True)\n",
    "data_loader = DataLoader(tokenized_dict['test'], collate_fn=data_collator, batch_size=128)\n",
    "start = time.time()\n",
    "df_calibrated_predictions = predict_data_loader(calibration_module, data_loader)\n",
    "end = time.time()\n",
    "\n",
    "print('elapsed: ', end - start)\n",
    "print(df_calibrated_predictions.shape)\n",
    "df_calibrated_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.11510791366906\n",
      "Precision: 61.119791666666664\n",
      "Recall: 58.04597701149425\n",
      "F1 Score: 57.22824498586048\n",
      "Confusion Matrix:\n",
      "[[14  2 22  5]\n",
      " [ 1 19  7  2]\n",
      " [ 4  3 29  7]\n",
      " [ 2  0  6 16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44        43\n",
      "           1       0.79      0.66      0.72        29\n",
      "           2       0.45      0.67      0.54        43\n",
      "           3       0.53      0.67      0.59        24\n",
      "\n",
      "    accuracy                           0.56       139\n",
      "   macro avg       0.61      0.58      0.57       139\n",
      "weighted avg       0.60      0.56      0.55       139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = df_calibrated_predictions['original_labels']\n",
    "y_pred = df_calibrated_predictions['pred_labels']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Precision:\", precision*100)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Recall:\", recall*100)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"F1 Score:\", f1*100)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>labels</th>\n",
       "      <th>softmax_prob</th>\n",
       "      <th>softmax_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should Social Security Be Privatized? Social S...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5773278474807739, 0.13025356829166412, 0.24...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can Alternative Energy Effectively Replace Fos...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5700161457061768, 0.04516660422086716, 0.27...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Should the United States Maintain Its Embargo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.10270910710096359, 0.061203762888908386, 0....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Should the United States Return to a Gold Stan...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.18370606005191803, 0.041861020028591156, 0....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is Obesity a Disease? Treatment for obesity an...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.11896917223930359, 0.01811995729804039, 0.1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input  labels  \\\n",
       "0  Should Social Security Be Privatized? Social S...       0   \n",
       "1  Can Alternative Energy Effectively Replace Fos...       0   \n",
       "2  Should the United States Maintain Its Embargo ...       1   \n",
       "3  Should the United States Return to a Gold Stan...       3   \n",
       "4  Is Obesity a Disease? Treatment for obesity an...       3   \n",
       "\n",
       "                                        softmax_prob  softmax_preds  \n",
       "0  [0.5773278474807739, 0.13025356829166412, 0.24...              0  \n",
       "1  [0.5700161457061768, 0.04516660422086716, 0.27...              0  \n",
       "2  [0.10270910710096359, 0.061203762888908386, 0....              3  \n",
       "3  [0.18370606005191803, 0.041861020028591156, 0....              3  \n",
       "4  [0.11896917223930359, 0.01811995729804039, 0.1...              3  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>original_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5756800174713135, 0.1309400051832199, 0.245...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5684800148010254, 0.04566999897360802, 0.27...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.10339999943971634, 0.06179000064730644, 0.2...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.18422000110149384, 0.042319998145103455, 0....</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.11984000355005264, 0.01844000071287155, 0.1...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              scores  original_labels  \\\n",
       "0  [0.5756800174713135, 0.1309400051832199, 0.245...                0   \n",
       "1  [0.5684800148010254, 0.04566999897360802, 0.27...                0   \n",
       "2  [0.10339999943971634, 0.06179000064730644, 0.2...                1   \n",
       "3  [0.18422000110149384, 0.042319998145103455, 0....                3   \n",
       "4  [0.11984000355005264, 0.01844000071287155, 0.1...                3   \n",
       "\n",
       "   pred_labels  \n",
       "0            0  \n",
       "1            0  \n",
       "2            3  \n",
       "3            3  \n",
       "4            3  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calibrated_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_soft_human.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['labels'] = test_df['labels'].tolist()\n",
    "test_df['uncalib_scores'] = softmax_prob\n",
    "test_df['uncalib_preds'] = softmax_pred\n",
    "test_df['calib_scores'] = df_calibrated_predictions['scores'].tolist()\n",
    "test_df['calib_preds'] = df_calibrated_predictions['pred_labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('results_baseline_roberta_human.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlt",
   "language": "python",
   "name": "hlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
