{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification multi-perspective approach RoBERTa-large LLMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting no majority instances \n",
    "def clean_data(df, col):\n",
    "     df = df.loc[~(df[col] == 'No Majority')] \n",
    "     return df\n",
    "\n",
    "\n",
    " train = clean_data(train_df, 'majority_llm_noninst')\n",
    " test = clean_data(test_df, 'majority_llm_noninst')\n",
    " val = clean_data(val_df, 'majority_llm_noninst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label mapping\n",
    "labels = ['Pro', 'Against', 'Neutral', 'Not-about']\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id,label in enumerate(labels)}\n",
    "label2id = {label:id for id,label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "train = Dataset.from_pandas(train)\n",
    "val = Dataset.from_pandas(val)\n",
    "test = Dataset.from_pandas(test)\n",
    "\n",
    "dataset = DatasetDict() \n",
    "dataset['train'] = train\n",
    "dataset['val'] = val\n",
    "dataset['test'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-large'\n",
    "model_name_filename = model_name.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fc4dd163ea42749655afb94842a45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/505 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e59e48e2c9147958af0493ad654bab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9aa622bfa414cc7bcf3c624a6ad367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#parsing soft labels\n",
    "\n",
    "\n",
    "def parse_soft_labels(example):\n",
    "    example['soft_labels_noninst'] = ast.literal_eval(example['soft_labels_noninst'])\n",
    "    return example\n",
    "\n",
    "\n",
    "train = train.map(parse_soft_labels)\n",
    "test = test.map(parse_soft_labels)\n",
    "val = val.map(parse_soft_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    # Tokenize the input text and map the 'soft_labels' column to 'labels'\n",
    "    tokenized_inputs = tokenizer(examples['Input'], padding='max_length', truncation=True, max_length=512)\n",
    "    tokenized_inputs['labels'] = examples['soft_labels_noninst']  # Rename 'soft_labels' to 'labels'\n",
    "    return tokenized_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7cd8708e4946ce9eadcd0202a803d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/505 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8d23f55c61492cb23d1fb936d7eb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized = train.map(tokenize_func, batched = True)\n",
    "val_tokenized = val.map(tokenize_func, batched = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['docID', 'Query', 'docTitle', 'doc', 'Input', 'labels', 'majority_label', 'Prompt', 'olmo', 'olmo_instruct', 'llama', 'llama_instruct', 'mistral_instruct', 'mistral', 'llm_labels_noninstruct', 'llm_labels_instruct', 'majority_llm_noninst', 'majority_llm_inst', 'label_indices_instruct', 'label_indices_noninstruct', 'soft_labels_noninst', 'soft_labels_inst', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 505\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized.set_format('torch', columns =['input_ids', 'attention_mask', 'labels'])\n",
    "val_tokenized.set_format('torch', columns = ['input_ids',  'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.6000, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=len(train_tokenized['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"./multiclassification/{model_name_filename}/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition soft loss function\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    Compute softmax probabilities from logits.\n",
    "    \n",
    "    Parameters:\n",
    "    - logits: A numpy array of shape (n, num_classes) containing the logits.\n",
    "    \n",
    "    Returns:\n",
    "    - probabilities: A numpy array of shape (n, num_classes) containing the softmax probabilities.\n",
    "    \"\"\"\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "def soft_loss_function(true_probabilities, predicted_logits):\n",
    "    \"\"\"\n",
    "    Compute the soft loss function (cross-entropy with soft labels) using PyTorch tensors.\n",
    "    \n",
    "    Parameters:\n",
    "    - true_probabilities: A PyTorch tensor of shape (n, num_classes) containing the true probability distributions.\n",
    "    - predicted_logits: A PyTorch tensor of shape (n, num_classes) containing the logits from the model.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: The computed soft loss.\n",
    "    \"\"\"\n",
    "   \n",
    "    predicted_probabilities = torch.nn.functional.softmax(predicted_logits, dim=-1)\n",
    "    \n",
    "   \n",
    "    epsilon = 1e-15\n",
    "    predicted_probabilities = torch.clamp(predicted_probabilities, epsilon, 1. - epsilon)\n",
    "    \n",
    "    \n",
    "    loss = -torch.sum(true_probabilities * torch.log(predicted_probabilities))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        Compute the loss for the model. This uses the soft_loss_function.\n",
    "\n",
    "        Parameters:\n",
    "        - model: The model to evaluate.\n",
    "        - inputs: A dictionary of inputs to the model.\n",
    "        - return_outputs: Whether to return model outputs along with loss.\n",
    "\n",
    "        Returns:\n",
    "        - loss: The computed loss.\n",
    "        - outputs (optional): The model outputs, if return_outputs is True.\n",
    "        \"\"\"\n",
    "        true_probabilities = inputs.pop(\"labels\")\n",
    "        \n",
    "      \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits \n",
    "        \n",
    "       \n",
    "        true_probabilities = true_probabilities.to(logits.device) \n",
    "       \n",
    "        \n",
    "       \n",
    "        \n",
    "        loss = soft_loss_function(true_probabilities, logits)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./multiclassification/roberta-large/results/tokenizer_config.json',\n",
       " './multiclassification/roberta-large/results/special_tokens_map.json',\n",
       " './multiclassification/roberta-large/results/vocab.json',\n",
       " './multiclassification/roberta-large/results/merges.txt',\n",
       " './multiclassification/roberta-large/results/added_tokens.json',\n",
       " './multiclassification/roberta-large/results/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc0b963637a40ab851c3829262f642a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test = test.map(tokenize_func, batched=True)\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting\n",
    "def predict(texts, model, tokenizer, device):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "batch_size = 8  \n",
    "\n",
    "for i in range(0, len(test), batch_size):\n",
    "    batch = test[i:i+batch_size]\n",
    "    batch_texts = batch['Input']\n",
    "    batch_predictions = predict(batch_texts, model, tokenizer, device)\n",
    "    all_predictions.extend(batch_predictions)\n",
    "    all_labels.extend(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "# Apply softmax to predictions\n",
    "softmax_predictions = softmax(all_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted_scores'] = all_predictions.tolist()\n",
    "df_test['Predicted_Softmax_scores'] = softmax_predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predicted_labels'] = df_test['Predicted_scores'].apply(lambda x: x.index(max(x)))\n",
    "df_test['predicted_softmax_labels'] = df_test['Predicted_Softmax_scores'].apply(lambda x: x.index(max(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "test = Dataset.from_pandas(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QID_x', 'Topic', 'Query', 'docID', 'docURL', 'docTitle', 'docCont', 'engineID', 'rank', 'answer1', 'answer2', 'answer3', 'If there is a link-broken option', 'majority_label', 'labels', 'Input', 'Input_length', 'docCont_length', 'gpt_summaries', 'doc', 'Prompt', 'olmo_instruct', 'olmo', 'llama_instruct', 'llama', 'mistral', 'mistral_instruct', 'llm_labels_noninstruct', 'llm_labels_instruct', 'majority_llm_noninst', 'majority_llm_inst', 'label_indices_instruct', 'label_indices_noninstruct', 'soft_labels_noninst', 'soft_labels_inst', '__index_level_0__', 'Predicted_scores', 'Predicted_Softmax_scores', 'predicted_labels', 'predicted_softmax_labels'],\n",
       "    num_rows: 102\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "label_ecnoding_multip = {'Pro': 0,\n",
    "'Against': 1,\n",
    "'Neutral': 2,\n",
    "'Not-about': 3,}\n",
    "\n",
    "\n",
    "m_test['true_labels'] = m_test['majority_llm_noninst'].map(label_ecnoding_multip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate classification metrics (accuracy, precision, recall, f1, confusion matrix)\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def calculate_confidences(df, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Calculate confidence scores and update the DataFrame with a new column.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame with input data\n",
    "    - model: Trained model with a method to get logits\n",
    "    - tokenizer: Tokenizer to preprocess text\n",
    "    \n",
    "    Returns:\n",
    "    - df: Updated DataFrame with a 'confidence_scores' column\n",
    "    \"\"\"\n",
    "    confidences = []\n",
    "\n",
    "    model.eval()  \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Input']  \n",
    "        \n",
    "  \n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = F.softmax(logits, dim=-1)  \n",
    "            probabilities = probabilities.cpu().numpy().flatten()  \n",
    "            \n",
    "            \n",
    "            max_prob = np.max(probabilities)\n",
    "            confidences.append(max_prob)\n",
    "    \n",
    "   \n",
    "    df['confidence_scores'] = confidences\n",
    "    return df\n",
    "\n",
    "\n",
    "m_test = calculate_confidences(m_test, model, tokenizer)\n",
    "\n",
    "\n",
    "y_true = m_test['true_labels']\n",
    "y_pred = m_test['predicted_labels']\n",
    "confidence_scores = m_test['confidence_scores']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy * 100)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Precision:\", precision * 100)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Recall:\", recall * 100)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"F1 Score:\", f1 * 100)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Average Confidence Score\n",
    "avg_confidence = np.mean(confidence_scores)\n",
    "print(\"Average Confidence Score:\", avg_confidence * 100)\n",
    "\n",
    "# Confidence for Correct and Incorrect Predictions\n",
    "correct_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred == true])\n",
    "incorrect_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred != true])\n",
    "\n",
    "print(\"Average Confidence for Correct Predictions:\", correct_confidence * 100)\n",
    "print(\"Average Confidence for Incorrect Predictions:\", incorrect_confidence * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 61.76470588235294\n",
    "Precision: 15.441176470588236\n",
    "Recall: 25.0\n",
    "F1 Score: 19.090909090909093\n",
    "Confusion Matrix:\n",
    "[[63  0  0  0]\n",
    " [13  0  0  0]\n",
    " [ 6  0  0  0]\n",
    " [20  0  0  0]]\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.62      1.00      0.76        63\n",
    "           1       0.00      0.00      0.00        13\n",
    "           2       0.00      0.00      0.00         6\n",
    "           3       0.00      0.00      0.00        20\n",
    "\n",
    "    accuracy                           0.62       102\n",
    "   macro avg       0.15      0.25      0.19       102\n",
    "weighted avg       0.38      0.62      0.47       102\n",
    "\n",
    "Average Confidence Score: 43.76310706138611\n",
    "Average Confidence for Correct Predictions: 44.1640055368817\n",
    "Average Confidence for Incorrect Predictions: 43.115509320528076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define soft loss function and calibration module\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    Compute softmax probabilities from logits.\n",
    "    \n",
    "    Parameters:\n",
    "    - logits: A numpy array of shape (n, num_classes) containing the logits.\n",
    "    \n",
    "    Returns:\n",
    "    - probabilities: A numpy array of shape (n, num_classes) containing the softmax probabilities.\n",
    "    \"\"\"\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "def soft_loss_function(true_probabilities, predicted_logits):\n",
    "    \"\"\"\n",
    "    Compute the soft loss function (cross-entropy with soft labels) using PyTorch tensors.\n",
    "    \n",
    "    Parameters:\n",
    "    - true_probabilities: A PyTorch tensor of shape (n, num_classes) containing the true probability distributions.\n",
    "    - predicted_logits: A PyTorch tensor of shape (n, num_classes) containing the logits from the model.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: The computed soft loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_probabilities = torch.nn.functional.softmax(predicted_logits, dim=-1)\n",
    "    \n",
    "  \n",
    "    epsilon = 1e-15\n",
    "    predicted_probabilities = torch.clamp(predicted_probabilities, epsilon, 1. - epsilon)\n",
    "    \n",
    "    \n",
    "    loss = -torch.sum(true_probabilities * torch.log(predicted_probabilities))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "class TemperatureScalingCalibration(nn.Module):\n",
    "    def __init__(self, model_path: str, tokenizer, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.model_path = model_path\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "       \n",
    "        self.temperature = nn.Parameter(torch.ones(1)) \n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.temperature.to(self.device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"Forward method that returns softmax-ed confidence scores.\"\"\"\n",
    "        logits = self.forward_logit(input_ids, attention_mask)\n",
    "        scaled_logits = logits / self.temperature\n",
    "        scores = nn.functional.softmax(scaled_logits, dim=-1)\n",
    "        return scores\n",
    "\n",
    "    def forward_logit(self, input_ids, attention_mask):\n",
    "        \"\"\"Forward method that returns logits, to be used with cross-entropy loss.\"\"\"\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        ).logits\n",
    "        return outputs\n",
    "\n",
    "    def fit(self, dataset_tokenized, n_epochs: int = 3, batch_size: int = 64, lr: float = 0.01):\n",
    "        \"\"\"Fits the temperature scaling parameter.\"\"\"\n",
    "        data_collator = DataCollatorWithPadding(self.tokenizer, padding=True)\n",
    "        data_loader = DataLoader(dataset_tokenized, collate_fn=data_collator, batch_size=batch_size)\n",
    "\n",
    "        self.freeze_base_model()\n",
    "      \n",
    "    \n",
    "        optimizer = optim.SGD(self.parameters(), lr=lr)\n",
    "\n",
    "     \n",
    "        self.train()\n",
    "\n",
    "        for epoch in trange(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for examples in data_loader:\n",
    "                \n",
    "                input_ids = examples['input_ids'].to(self.device)\n",
    "                attention_mask = examples['attention_mask'].to(self.device)\n",
    "                soft_labels = examples['labels'].to(self.device)  \n",
    "                \n",
    "            \n",
    "                self.zero_grad()\n",
    "                logits = self.forward_logit(input_ids, attention_mask)\n",
    "                \n",
    "               \n",
    "                scaled_logits = logits / self.temperature\n",
    "                \n",
    "                \n",
    "                loss = soft_loss_function(soft_labels, scaled_logits)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "               \n",
    "                epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "         \n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss / len(dataset_tokenized)}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def freeze_base_model(self):\n",
    "        \"\"\"Remember to freeze base model's parameters when training temperature scaler.\"\"\"\n",
    "        self.model.eval()\n",
    "        for parameter in self.model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./multiclassification/roberta-large/results/tokenizer_config.json',\n",
       " './multiclassification/roberta-large/results/special_tokens_map.json',\n",
       " './multiclassification/roberta-large/results/vocab.json',\n",
       " './multiclassification/roberta-large/results/merges.txt',\n",
       " './multiclassification/roberta-large/results/added_tokens.json',\n",
       " './multiclassification/roberta-large/results/tokenizer.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemperatureScalingCalibration(\n",
       "  (model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "calibration_module = TemperatureScalingCalibration(model_path=output_dir, tokenizer=tokenizer, device=device)\n",
    "calibration_module.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    # Tokenize the input text and map the 'soft_labels' column to 'labels'\n",
    "    tokenized_inputs = tokenizer(examples['Input'], padding='max_length', truncation=True, max_length=512)\n",
    "    tokenized_inputs['labels'] = examples['soft_labels_noninst']  # Rename 'soft_labels' to 'labels'\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52d55966d8c4358bd7ff7daa3782264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_tokenized_cal = val.map(tokenize_func, batched = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tokenized_cal.set_format('torch', columns = ['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:03<00:15,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6, Loss: 65.47042158461109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:06<00:12,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6, Loss: 65.80075206953225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:09<00:09,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6, Loss: 66.68073080003876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:12<00:06,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6, Loss: 66.09461463849568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:15<00:03,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6, Loss: 66.18117082733468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:18<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6, Loss: 66.30719953713958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemperatureScalingCalibration(\n",
       "  (model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_module.fit(val_tokenized_cal,n_epochs=6, batch_size=64, lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemperatureScalingCalibration(\n",
       "  (model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cal(texts, model, tokenizer, device):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']}  \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs)  \n",
    "    return logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "batch_size = 8  \n",
    "\n",
    "for i in range(0, len(test), batch_size):\n",
    "    batch = test[i:i+batch_size]\n",
    "    batch_texts = batch['Input']\n",
    "    batch_predictions = predict_cal(batch_texts, calibration_module, tokenizer, device)\n",
    "    all_predictions.extend(batch_predictions)\n",
    "    all_labels.extend(batch['labels']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "# Apply softmax to predictions\n",
    "softmax_predictions = softmax(all_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cal = test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cal['Predicted_scores'] = all_predictions.tolist()\n",
    "df_test_cal['Predicted_Softmax_scores'] = softmax_predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cal['predicted_labels'] = df_test['Predicted_scores'].apply(lambda x: x.index(max(x)))\n",
    "df_test_cal['predicted_softmax_labels'] = df_test['Predicted_Softmax_scores'].apply(lambda x: x.index(max(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "test_cal = Dataset.from_pandas(df_test_cal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ecnoding_multip = {'Pro': 0,\n",
    "'Against': 1,\n",
    "'Neutral': 2,\n",
    "'Not-about': 3,} \n",
    "\n",
    "\n",
    "m_test_cal['true_labels'] = m_test_cal['majority_llm_noninst'].map(label_ecnoding_multip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def calculate_confidences_cal(df, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Calculate confidence scores and update the DataFrame with a new column.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame with input data\n",
    "    - model: Trained model with a method to get logits\n",
    "    - tokenizer: Tokenizer to preprocess text\n",
    "    \n",
    "    Returns:\n",
    "    - df: Updated DataFrame with a 'confidence_scores' column\n",
    "    \"\"\"\n",
    "    confidences = []\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Input']  # Adjust this if your text column is named differently\n",
    "        \n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = F.softmax(logits, dim=-1)  # Apply softmax to get probabilities\n",
    "            probabilities = probabilities.cpu().numpy().flatten()  # Convert to numpy array and flatten\n",
    "            \n",
    "            # Get the maximum probability (confidence) and corresponding class index\n",
    "            max_prob = np.max(probabilities)\n",
    "            confidences.append(max_prob)\n",
    "    \n",
    "    # Add confidence scores to the DataFrame\n",
    "    df['confidence_scores'] = confidences\n",
    "    return df\n",
    "\n",
    "\n",
    "m_test_cal = calculate_confidences_cal(m_test_cal, model, tokenizer)\n",
    "\n",
    "# Proceed with metrics calculation\n",
    "y_true = m_test_cal['true_labels']\n",
    "y_pred = m_test_cal['predicted_labels']\n",
    "confidence_scores = m_test_cal['confidence_scores']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy * 100)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Precision:\", precision * 100)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Recall:\", recall * 100)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"F1 Score:\", f1 * 100)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Average Confidence Score\n",
    "avg_confidence = np.mean(confidence_scores)\n",
    "print(\"Average Confidence Score:\", avg_confidence * 100)\n",
    "\n",
    "# Confidence for Correct and Incorrect Predictions\n",
    "correct_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred == true])\n",
    "incorrect_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred != true])\n",
    "\n",
    "print(\"Average Confidence for Correct Predictions:\", correct_confidence * 100)\n",
    "print(\"Average Confidence for Incorrect Predictions:\", incorrect_confidence * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 61.76470588235294\n",
    "Precision: 15.441176470588236\n",
    "Recall: 25.0\n",
    "F1 Score: 19.090909090909093\n",
    "Confusion Matrix:\n",
    "[[63  0  0  0]\n",
    " [13  0  0  0]\n",
    " [ 6  0  0  0]\n",
    " [20  0  0  0]]\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.62      1.00      0.76        63\n",
    "           1       0.00      0.00      0.00        13\n",
    "           2       0.00      0.00      0.00         6\n",
    "           3       0.00      0.00      0.00        20\n",
    "\n",
    "    accuracy                           0.62       102\n",
    "   macro avg       0.15      0.25      0.19       102\n",
    "weighted avg       0.38      0.62      0.47       102\n",
    "\n",
    "Average Confidence Score: 43.76310706138611\n",
    "Average Confidence for Correct Predictions: 44.1640055368817\n",
    "Average Confidence for Incorrect Predictions: 43.115509320528076"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multip",
   "language": "python",
   "name": "multip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
