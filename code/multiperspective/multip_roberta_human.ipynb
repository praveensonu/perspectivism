{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification multi-perspective approach RoBERTa-large HHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['soft_labels'] = train['soft_labels'].apply(ast.literal_eval).tolist()\n",
    "test['soft_labels'] = test['soft_labels'].apply(ast.literal_eval).tolist()\n",
    "val['soft_labels'] = val['soft_labels'].apply(ast.literal_eval).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = Dataset.from_pandas(train)\n",
    "val = Dataset.from_pandas(val)\n",
    "test = Dataset.from_pandas(test)\n",
    "\n",
    "dataset = DatasetDict() \n",
    "dataset['train'] = train\n",
    "dataset['val'] = val\n",
    "dataset['test'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-large'\n",
    "model_name_filename = model_name.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    # Tokenize the input text and map the 'soft_labels' column to 'labels'\n",
    "    tokenized_inputs = tokenizer(examples['Input'], padding='max_length', truncation=True, max_length=512)\n",
    "    tokenized_inputs['labels'] = examples['soft_labels'] \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774047754da14b5b8ddcdee678dd2b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d9cf1f868b46f0bead5a800327d8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized = train.map(tokenize_func, batched = True)\n",
    "val_tokenized = val.map(tokenize_func, batched = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized.set_format('torch', columns =['input_ids', 'attention_mask', 'labels'])\n",
    "val_tokenized.set_format('torch', columns = ['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=len(train_tokenized['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"./multiclassification/{model_name_filename}/results/human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition soft loss function\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    Compute softmax probabilities from logits.\n",
    "    \n",
    "    Parameters:\n",
    "    - logits: A numpy array of shape (n, num_classes) containing the logits.\n",
    "    \n",
    "    Returns:\n",
    "    - probabilities: A numpy array of shape (n, num_classes) containing the softmax probabilities.\n",
    "    \"\"\"\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "def soft_loss_function(true_probabilities, predicted_logits):\n",
    "    \"\"\"\n",
    "    Compute the soft loss function (cross-entropy with soft labels) using PyTorch tensors.\n",
    "    \n",
    "    Parameters:\n",
    "    - true_probabilities: A PyTorch tensor of shape (n, num_classes) containing the true probability distributions.\n",
    "    - predicted_logits: A PyTorch tensor of shape (n, num_classes) containing the logits from the model.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: The computed soft loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_probabilities = torch.nn.functional.softmax(predicted_logits, dim=-1)\n",
    "    \n",
    "   \n",
    "    epsilon = 1e-15\n",
    "    predicted_probabilities = torch.clamp(predicted_probabilities, epsilon, 1. - epsilon)\n",
    "    \n",
    "   \n",
    "    loss = -torch.sum(true_probabilities * torch.log(predicted_probabilities))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        Compute the loss for the model. This uses the soft_loss_function.\n",
    "\n",
    "        Parameters:\n",
    "        - model: The model to evaluate.\n",
    "        - inputs: A dictionary of inputs to the model.\n",
    "        - return_outputs: Whether to return model outputs along with loss.\n",
    "\n",
    "        Returns:\n",
    "        - loss: The computed loss.\n",
    "        - outputs (optional): The model outputs, if return_outputs is True.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        \n",
    "      \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "       \n",
    "        true_probabilities = labels \n",
    "        logits = logits \n",
    "        \n",
    "        \n",
    "        loss = soft_loss_function(true_probabilities, logits)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./multiclassification/roberta-large/results/human/tokenizer_config.json',\n",
       " './multiclassification/roberta-large/results/human/special_tokens_map.json',\n",
       " './multiclassification/roberta-large/results/human/vocab.json',\n",
       " './multiclassification/roberta-large/results/human/merges.txt',\n",
       " './multiclassification/roberta-large/results/human/added_tokens.json',\n",
       " './multiclassification/roberta-large/results/human/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dd7b00569e441fb9c3c7454cba03f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test = test.map(tokenize_func, batched=True)\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts, model, tokenizer, device):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "batch_size = 8\n",
    "\n",
    "for i in range(0, len(test), batch_size):\n",
    "    batch = test[i:i+batch_size]\n",
    "    batch_texts = batch['Input']\n",
    "    batch_predictions = predict(batch_texts, model, tokenizer, device)\n",
    "    all_predictions.extend(batch_predictions)\n",
    "    all_labels.extend(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "# Apply softmax to predictions\n",
    "softmax_predictions = softmax(all_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted_scores'] = all_predictions.tolist()\n",
    "df_test['Predicted_Softmax_scores'] = softmax_predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predicted_labels'] = df_test['Predicted_scores'].apply(lambda x: x.index(max(x)))\n",
    "df_test['predicted_softmax_labels'] = df_test['Predicted_Softmax_scores'].apply(lambda x: x.index(max(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "test = Dataset.from_pandas(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'docID', 'Query', 'docTitle', 'doc', 'Input', 'labels', 'majority_label', 'label_index', 'soft_labels', 'Predicted_scores', 'Predicted_Softmax_scores', 'predicted_labels', 'predicted_softmax_labels'],\n",
       "    num_rows: 139\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "label_ecnoding_multip = {'Pro': 0,\n",
    "'Against': 1,\n",
    "'Neutral': 2,\n",
    "'Not-about': 3,}\n",
    "\n",
    "\n",
    "m_test['true_labels'] = m_test['majority_label'].map(label_ecnoding_multip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.431654676258994\n",
      "Precision: 63.553892620752436\n",
      "Recall: 62.83664127238706\n",
      "F1 Score: 61.90897381135846\n",
      "Confusion Matrix:\n",
      "[[26  0 11  6]\n",
      " [ 5 22  0  2]\n",
      " [ 9  2 19 13]\n",
      " [ 6  0  1 17]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58        43\n",
      "           1       0.92      0.76      0.83        29\n",
      "           2       0.61      0.44      0.51        43\n",
      "           3       0.45      0.71      0.55        24\n",
      "\n",
      "    accuracy                           0.60       139\n",
      "   macro avg       0.64      0.63      0.62       139\n",
      "weighted avg       0.63      0.60      0.61       139\n",
      "\n",
      "Average Confidence Score: 48.760855197906494\n",
      "Average Confidence for Correct Predictions: 51.40508913568088\n",
      "Average Confidence for Incorrect Predictions: 44.722386327656835\n"
     ]
    }
   ],
   "source": [
    "#calculate classification metrics \n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def calculate_confidences(df, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Calculate confidence scores and update the DataFrame with a new column.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame with input data\n",
    "    - model: Trained model with a method to get logits\n",
    "    - tokenizer: Tokenizer to preprocess text\n",
    "    \n",
    "    Returns:\n",
    "    - df: Updated DataFrame with a 'confidence_scores' column\n",
    "    \"\"\"\n",
    "    confidences = []\n",
    "\n",
    "    model.eval() \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Input']  \n",
    "        \n",
    "       \n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = F.softmax(logits, dim=-1)  \n",
    "            probabilities = probabilities.cpu().numpy().flatten()  \n",
    "            \n",
    "           \n",
    "            max_prob = np.max(probabilities)\n",
    "            confidences.append(max_prob)\n",
    "    \n",
    "   \n",
    "    df['confidence_scores'] = confidences\n",
    "    return df\n",
    "\n",
    "\n",
    "m_test = calculate_confidences(m_test, model, tokenizer)\n",
    "\n",
    "# Proceed with metrics calculation\n",
    "y_true = m_test['true_labels']\n",
    "y_pred = m_test['predicted_labels']\n",
    "confidence_scores = m_test['confidence_scores']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy * 100)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Precision:\", precision * 100)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Recall:\", recall * 100)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"F1 Score:\", f1 * 100)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Average Confidence Score\n",
    "avg_confidence = np.mean(confidence_scores)\n",
    "print(\"Average Confidence Score:\", avg_confidence * 100)\n",
    "\n",
    "# Confidence for Correct and Incorrect Predictions\n",
    "correct_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred == true])\n",
    "incorrect_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred != true])\n",
    "\n",
    "print(\"Average Confidence for Correct Predictions:\", correct_confidence * 100)\n",
    "print(\"Average Confidence for Incorrect Predictions:\", incorrect_confidence * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soft loss function definition and temperature module\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    Compute softmax probabilities from logits.\n",
    "    \n",
    "    Parameters:\n",
    "    - logits: A numpy array of shape (n, num_classes) containing the logits.\n",
    "    \n",
    "    Returns:\n",
    "    - probabilities: A numpy array of shape (n, num_classes) containing the softmax probabilities.\n",
    "    \"\"\"\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "def soft_loss_function(true_probabilities, predicted_logits):\n",
    "    \"\"\"\n",
    "    Compute the soft loss function (cross-entropy with soft labels) using PyTorch tensors.\n",
    "    \n",
    "    Parameters:\n",
    "    - true_probabilities: A PyTorch tensor of shape (n, num_classes) containing the true probability distributions.\n",
    "    - predicted_logits: A PyTorch tensor of shape (n, num_classes) containing the logits from the model.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: The computed soft loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_probabilities = torch.nn.functional.softmax(predicted_logits, dim=-1)\n",
    "    \n",
    "\n",
    "    epsilon = 1e-15\n",
    "    predicted_probabilities = torch.clamp(predicted_probabilities, epsilon, 1. - epsilon)\n",
    "    \n",
    "  \n",
    "    loss = -torch.sum(true_probabilities * torch.log(predicted_probabilities))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "class TemperatureScalingCalibration(nn.Module):\n",
    "    def __init__(self, model_path: str, tokenizer, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.model_path = model_path\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    \n",
    "        self.temperature = nn.Parameter(torch.ones(1)) \n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.temperature.to(self.device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"Forward method that returns softmax-ed confidence scores.\"\"\"\n",
    "        logits = self.forward_logit(input_ids, attention_mask)\n",
    "        scaled_logits = logits / self.temperature\n",
    "        scores = nn.functional.softmax(scaled_logits, dim=-1)\n",
    "        return scores\n",
    "\n",
    "    def forward_logit(self, input_ids, attention_mask):\n",
    "        \"\"\"Forward method that returns logits, to be used with cross-entropy loss.\"\"\"\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        ).logits\n",
    "        return outputs\n",
    "\n",
    "    def fit(self, dataset_tokenized, n_epochs: int = 3, batch_size: int = 64, lr: float = 0.01):\n",
    "        \"\"\"Fits the temperature scaling parameter.\"\"\"\n",
    "        data_collator = DataCollatorWithPadding(self.tokenizer, padding=True)\n",
    "        data_loader = DataLoader(dataset_tokenized, collate_fn=data_collator, batch_size=batch_size)\n",
    "\n",
    "        self.freeze_base_model()\n",
    "      \n",
    "  \n",
    "        optimizer = optim.SGD(self.parameters(), lr=lr)\n",
    "\n",
    "      \n",
    "        self.train()\n",
    "\n",
    "        for epoch in trange(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for examples in data_loader:\n",
    "                \n",
    "                input_ids = examples['input_ids'].to(self.device)\n",
    "                attention_mask = examples['attention_mask'].to(self.device)\n",
    "                soft_labels = examples['labels'].to(self.device)  \n",
    "                \n",
    "                \n",
    "                self.zero_grad()\n",
    "                logits = self.forward_logit(input_ids, attention_mask)\n",
    "                \n",
    "                \n",
    "                scaled_logits = logits / self.temperature\n",
    "                \n",
    "                \n",
    "                loss = soft_loss_function(soft_labels, scaled_logits)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                \n",
    "                epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        \n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss / len(dataset_tokenized)}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def freeze_base_model(self):\n",
    "        \"\"\"Remember to freeze base model's parameters when training temperature scaler.\"\"\"\n",
    "        self.model.eval()\n",
    "        for parameter in self.model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./multiclassification/roberta-large/results/human/tokenizer_config.json',\n",
       " './multiclassification/roberta-large/results/human/special_tokens_map.json',\n",
       " './multiclassification/roberta-large/results/human/vocab.json',\n",
       " './multiclassification/roberta-large/results/human/merges.txt',\n",
       " './multiclassification/roberta-large/results/human/added_tokens.json',\n",
       " './multiclassification/roberta-large/results/human/tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemperatureScalingCalibration(\n",
       "  (model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "calibration_module = TemperatureScalingCalibration(model_path=output_dir, tokenizer=tokenizer, device=device)\n",
    "calibration_module.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    # Tokenize the input text and map the 'soft_labels' column to 'labels'\n",
    "    tokenized_inputs = tokenizer(examples['Input'], padding='max_length', truncation=True, max_length=512)\n",
    "    tokenized_inputs['labels'] = examples['soft_labels'] \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b13414ab15413d89897d53699fa330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_tokenized_cal = val.map(tokenize_func, batched = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tokenized_cal.set_format('torch', columns = ['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:04<00:21,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6, Loss: 72.29785212509924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:08<00:17,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6, Loss: 72.93254679398571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:12<00:12,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6, Loss: 71.83638473894956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:17<00:08,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6, Loss: 72.12693185600446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:21<00:04,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6, Loss: 71.6213482575451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6, Loss: 71.56138588198655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemperatureScalingCalibration(\n",
       "  (model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_module.fit(val_tokenized_cal,n_epochs=6, batch_size=64, lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemperatureScalingCalibration(\n",
       "  (model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_module.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cal(texts, model, tokenizer, device):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items() if k in ['input_ids', 'attention_mask']} \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs)  \n",
    "    return logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "batch_size = 8  \n",
    "\n",
    "for i in range(0, len(test), batch_size):\n",
    "    batch = test[i:i+batch_size]\n",
    "    batch_texts = batch['Input']\n",
    "    batch_predictions = predict_cal(batch_texts, calibration_module, tokenizer, device)\n",
    "    all_predictions.extend(batch_predictions)\n",
    "    all_labels.extend(batch['labels']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "# Apply softmax to predictions\n",
    "softmax_predictions = softmax(all_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cal = test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cal['Predicted_scores'] = all_predictions.tolist()\n",
    "df_test_cal['Predicted_Softmax_scores'] = softmax_predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cal['predicted_labels'] = df_test['Predicted_scores'].apply(lambda x: x.index(max(x)))\n",
    "df_test_cal['predicted_softmax_labels'] = df_test['Predicted_Softmax_scores'].apply(lambda x: x.index(max(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "test_cal = Dataset.from_pandas(df_test_cal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ecnoding_multip = {'Pro': 0,\n",
    "'Against': 1,\n",
    "'Neutral': 2,\n",
    "'Not-about': 3,} \n",
    "\n",
    "\n",
    "m_test_cal['true_labels'] = m_test_cal['majority_label'].map(label_ecnoding_multip)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.431654676258994\n",
      "Precision: 63.553892620752436\n",
      "Recall: 62.83664127238706\n",
      "F1 Score: 61.90897381135846\n",
      "Confusion Matrix:\n",
      "[[26  0 11  6]\n",
      " [ 5 22  0  2]\n",
      " [ 9  2 19 13]\n",
      " [ 6  0  1 17]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58        43\n",
      "           1       0.92      0.76      0.83        29\n",
      "           2       0.61      0.44      0.51        43\n",
      "           3       0.45      0.71      0.55        24\n",
      "\n",
      "    accuracy                           0.60       139\n",
      "   macro avg       0.64      0.63      0.62       139\n",
      "weighted avg       0.63      0.60      0.61       139\n",
      "\n",
      "Average Confidence Score: 48.760855197906494\n",
      "Average Confidence for Correct Predictions: 51.40508913568088\n",
      "Average Confidence for Incorrect Predictions: 44.722386327656835\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def calculate_confidences_cal(df, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Calculate confidence scores and update the DataFrame with a new column.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame with input data\n",
    "    - model: Trained model with a method to get logits\n",
    "    - tokenizer: Tokenizer to preprocess text\n",
    "    \n",
    "    Returns:\n",
    "    - df: Updated DataFrame with a 'confidence_scores' column\n",
    "    \"\"\"\n",
    "    confidences = []\n",
    "\n",
    "    model.eval()  \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['Input']  \n",
    "        \n",
    "     \n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = F.softmax(logits, dim=-1)  \n",
    "            probabilities = probabilities.cpu().numpy().flatten()  \n",
    "            \n",
    "           \n",
    "            max_prob = np.max(probabilities)\n",
    "            confidences.append(max_prob)\n",
    "    \n",
    "  \n",
    "    df['confidence_scores'] = confidences\n",
    "    return df\n",
    "\n",
    "\n",
    "m_test_cal = calculate_confidences_cal(m_test_cal, model, tokenizer)\n",
    "\n",
    "\n",
    "y_true = m_test_cal['true_labels']\n",
    "y_pred = m_test_cal['predicted_labels']\n",
    "confidence_scores = m_test_cal['confidence_scores']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy * 100)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Precision:\", precision * 100)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"Recall:\", recall * 100)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' averaging for multiclass\n",
    "print(\"F1 Score:\", f1 * 100)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Average Confidence Score\n",
    "avg_confidence = np.mean(confidence_scores)\n",
    "print(\"Average Confidence Score:\", avg_confidence * 100)\n",
    "\n",
    "# Confidence for Correct and Incorrect Predictions\n",
    "correct_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred == true])\n",
    "incorrect_confidence = np.mean([confidence for pred, true, confidence in zip(y_pred, y_true, confidence_scores) if pred != true])\n",
    "\n",
    "print(\"Average Confidence for Correct Predictions:\", correct_confidence * 100)\n",
    "print(\"Average Confidence for Incorrect Predictions:\", incorrect_confidence * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multip",
   "language": "python",
   "name": "multip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
